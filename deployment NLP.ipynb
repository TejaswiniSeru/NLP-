{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfnIOeyZYWQw",
        "outputId": "1f69fc62-a745-4b6a-bf9c-e236dc0c1d8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RWrvN9wiYknY"
      },
      "outputs": [],
      "source": [
        "import os, re\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "from transformers import BertForSequenceClassification\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
      ],
      "metadata": {
        "id": "bI0qqyfmtSuy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU7H-wJibqBo",
        "outputId": "c95dfaf6-2687-4cb3-e63d-57d680a218a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit\n",
        "!npm install localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKS1c8ZU2KY7",
        "outputId": "170d77f2-8933-4f90-e038-fbc0dabd7c44"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "\n",
        "import os, re\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "import random\n",
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "from transformers import BertForSequenceClassification\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "label_dict = {' drama ': 0,\n",
        " ' thriller ': 1,\n",
        " ' adult ': 2,\n",
        " ' documentary ': 3,\n",
        " ' comedy ': 4,\n",
        " ' crime ': 5,\n",
        " ' reality-tv ': 6,\n",
        " ' horror ': 7,\n",
        " ' sport ': 8,\n",
        " ' animation ': 9,\n",
        " ' action ': 10,\n",
        " ' fantasy ': 11,\n",
        " ' short ': 12,\n",
        " ' sci-fi ': 13,\n",
        " ' music ': 14,\n",
        " ' adventure ': 15,\n",
        " ' talk-show ': 16,\n",
        " ' western ': 17,\n",
        " ' family ': 18,\n",
        " ' mystery ': 19,\n",
        " ' history ': 20,\n",
        " ' news ': 21,\n",
        " ' biography ': 22,\n",
        " ' romance ': 23,\n",
        " ' game-show ': 24,\n",
        " ' musical ': 25,\n",
        " ' war ': 26}\n",
        "\n",
        "label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/projects/movie/finetuned_BERT_epoch_1.model\"\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "@st.cache_data\n",
        "def load_model(model_path=model_path):\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "                                                        num_labels=len(label_dict),\n",
        "                                                        output_attentions=False,\n",
        "                                                        output_hidden_states=False)\n",
        "\n",
        "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return tokenizer, model\n",
        "\n",
        "tokenizer, model = load_model(model_path)\n",
        "\n",
        "input_text = st.text_area('Movie Description', 'listening conversation doctor parents year old oscar learns nobody courage tell weeks live furious refuses speak anyone except straight talking rose lady pink meets hospital stairs christmas approaches rose uses fantastical experiences professional wrestler imagination wit charm allow oscar live life love full company friends pop corn einstein bacon childhood sweetheart peggy blue')\n",
        "\n",
        "if st.button('Get Genre'):\n",
        "\n",
        "    encoded_data = tokenizer.batch_encode_plus(\n",
        "        [input_text],\n",
        "        add_special_tokens=True,\n",
        "        return_attention_mask=True,\n",
        "        pad_to_max_length=True,\n",
        "        max_length=100,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    input_ids = encoded_data['input_ids']\n",
        "    attention_masks = encoded_data['attention_mask']\n",
        "\n",
        "    dataset = TensorDataset(input_ids, attention_masks)\n",
        "    dataloader = DataLoader(dataset,batch_size=1)\n",
        "\n",
        "    for batch in dataloader:\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "\n",
        "    inputs = {'input_ids':      batch[0],\n",
        "            'attention_mask': batch[1],\n",
        "            # 'labels':         batch[2],\n",
        "        }\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    preds_flat = np.argmax(outputs['logits'], axis=1).flatten()[0].item()\n",
        "\n",
        "    st.write(f'Predicted Movie Genre is =  {label_dict_inverse[preds_flat]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BUs7OJb2rbe",
        "outputId": "01c501a6-2234-46f2-9465-7b09072a9a20"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aE-ryBAL2uqH",
        "outputId": "c7433f69-4b33-414c-af4e-67803eccb2ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.190.140.112\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 4.459s\n",
            "your url is: https://quiet-geese-add.loca.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7CIUD-zm57Ct"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}